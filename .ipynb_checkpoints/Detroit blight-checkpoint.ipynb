{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detroit Blight\n",
    "A study notebook\n",
    "\n",
    "Overall plan <br>\n",
    "1) Load and explore incident data from the various files: violations, 311 calls, crime <br>\n",
    "2) Define 'houses' as  geographic entities, for example a 10 x 10 meter squares. Allocate incidents to houses. <br>\n",
    "3) Allocate known demolition permits to houses. Houses marked for demolition are regarded as blighted. <br>\n",
    "4) Train a model to predict which houses will be marked for demolition (=are blighted) <br>\n",
    " a) simple model by count of incidents\n",
    " b) intermediate model by count of incidents per category\n",
    "\n",
    "## Data\n",
    "    Downloaded these files. Using the local files in the code.\n",
    "https://github.com/uwescience/datasci_course_materials/blob/master/capstone/blight/data/detroit-blight-violations.csv\n",
    "https://github.com/uwescience/datasci_course_materials/blob/master/capstone/blight/data/detroit-311.csv\n",
    "https://github.com/uwescience/datasci_course_materials/blob/master/capstone/blight/data/detroit-crime.csv\n",
    "https://github.com/uwescience/datasci_course_materials/blob/master/capstone/blight/data/detroit-demolition-permits.tsv\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Prepare for data manipulation\n",
    "First define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(data.table)\n",
    "\n",
    "# Program idea: fit incident data to data frame. Select only relevant columns, and always use same names for them. \n",
    "# From incident data, derive unique locations of a given area = houses. House data: HouseId, Lat, Lon.\n",
    "\n",
    "loadDf <- function(fileName) {\n",
    "    basedir <-\n",
    "        \"C:/Users/setup/Documents/coursera/uw/datascience/capstone\"\n",
    "    assign(\"datadir\",(paste0(basedir, \"/data\")),.GlobalEnv)\n",
    "    assign(\"codedir\",(paste0(basedir, \"/code\")),.GlobalEnv)\n",
    "    setwd(datadir)\n",
    "    fullName <- paste0(datadir, \"/\", fileName)\n",
    "    df <- read.csv(fullName, stringsAsFactors = FALSE)\n",
    "    return(df)\n",
    "}\n",
    "\n",
    "loadDt <- function(fileName){\n",
    "    d <- loadDf(fileName)\n",
    "    d <- data.table(d)\n",
    "    return(d)\n",
    "}\n",
    "\n",
    "getBViol <- function(){\n",
    "    bv <- loadDt(\"detroit-blight-violations.csv\")\n",
    "    return(bv)\n",
    "}\n",
    "\n",
    "formatBv <- function(bv) {\n",
    "    bv <- subset(\n",
    "        bv,!(is.null(\"ViolationCode\")),select = c(\n",
    "            \"ViolationCode\", \"ViolDescription\",\n",
    "            \"ViolationAddress\",\"ViolationStreetNumber\", \"ViolationStreetName\", \"TicketIssuedDT\"\n",
    "        )\n",
    "    )\n",
    "    extractCoord <- function(bvsRow) {\n",
    "        # bvsRow is like ..., 2566 GRAND BLVD\\nDetroit, MI\\n(42.36318237000006, -83.09167672099994)\n",
    "        rowStr <- unlist(strsplit(toString(bvsRow),split = \"\\n\"))[3]\n",
    "        # Now we have something like (42.32544917300004, -83.06413908999997)\n",
    "        coord <- gsub(\"[()]\",\"\",rowStr)\n",
    "        coord <- unlist(strsplit(coord,split = \",\"))\n",
    "        coord <- c(coord[1], coord[2])\n",
    "        return(coord)\n",
    "    }\n",
    "    coord <- t(apply(bv,1,extractCoord))\n",
    "    # Add latitude and longitude as first columns\n",
    "    bv <- cbind(as.numeric(coord[,1]),as.numeric(coord[,2]),bv)\n",
    "    names(bv) <-\n",
    "        c(\"Lat\",\"Lon\",\"IncType\",\"ViolDescription\", \"VAddress\",\"VStrNr\",\"VStrName\",\"TicketIssueDT\")\n",
    "    return(bv)\n",
    "} # formatBv\n",
    "\n",
    "getD311 <- function() {\n",
    "    d311 <- loadDf(\"detroit-311.csv\")\n",
    "    #u311type <- unique(d311$issue_type,use.names = FALSE)\n",
    "    d311 <- subset(\n",
    "        d311,\n",
    "        select = c(\n",
    "            issue_type,ticket_closed_date_time,ticket_created_date_time,\n",
    "            address,lat,lng\n",
    "        )\n",
    "    )\n",
    "    # assign(\"u311type\",u311type,envir = .GlobalEnv)\n",
    "    n311 <- names(d311)\n",
    "    n311[1] <- \"IncType\"\n",
    "    n311[5] <- \"Lat\"\n",
    "    n311[6] <- \"Lon\"\n",
    "    names(d311) <- n311\n",
    "    d311$Lat <- as.numeric(d311$Lat)\n",
    "    d311$Lon <- as.numeric(d311$Lon)\n",
    "    d311 <- data.table(d311)\n",
    "    return(d311)\n",
    "}\n",
    "\n",
    "getCrime <- function(){\n",
    "    cr <- loadDf(\"detroit-crime.csv\")\n",
    "    cr <- subset(cr,select=c(\"CATEGORY\", \"LAT\", \"LON\"))\n",
    "    names(cr) <- c(\"IncType\", \"Lat\", \"Lon\")\n",
    "    return(cr)\n",
    "}\n",
    "\n",
    "formatForInc <- function(dt){\n",
    "    inc <- data.table(Lat = dt$Lat, Lon=dt$Lon) #possibly add IncType\n",
    "    return(inc)   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Build houses\n",
    "Now that the functions are defined, let's actually build the houses and limit to those within Detroit's boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OGR data source with driver: ESRI Shapefile \n",
      "Source: \"C:/Users/setup/Documents/coursera/uw/datascience/capstone/data/City Boundaries shapefile\", layer: \"geo_export_941b9f41-e08a-40db-ae36-d77a7046e1a5\"\n",
      "with 1 features\n",
      "It has 7 fields\n"
     ]
    }
   ],
   "source": [
    "debug(buildHouses3)\n",
    "buildHouses3 <- function(precision){\n",
    "    library(data.table)\n",
    "    bv <- getBViol()\n",
    "    bv <- formatBv(bv)\n",
    "    inc <- data.table()\n",
    "    inc <- rbind(inc, formatForInc(bv))\n",
    "    rm(bv)\n",
    "    d311 <- getD311()\n",
    "    inc <- rbind(inc, formatForInc(d311))\n",
    "    rm(d311)\n",
    "    cr <- getCrime()\n",
    "    inc <- rbind(inc, formatForInc(cr))\n",
    "    rm(cr)\n",
    "    # Remove clear geographic outliers. Coordinates from Detroit boundaries with a margin.\n",
    "    inc <- inc[Lat %between% c(42.25,42.5) & Lon %between% c(-83.3,-82.9)]\n",
    "    inc$Lat <- round(as.numeric(inc$Lat),digits=precision)\n",
    "    inc$Lon <- round(as.numeric(inc$Lon),digits=precision)\n",
    "    setkey(inc, Lat, Lon)\n",
    "    # The data table operator .N adds the number of incidents in the by group to every member of the group. \n",
    "    # We add it as a new column Count.\n",
    "    inc <- inc[,\":=\" (Count = .N), by= list(Lat, Lon)]\n",
    "    houses <- unique(inc)\n",
    "    rm(inc)\n",
    "    colnames(houses) <- c(\"Lat\", \"Lon\", \"Count\")\n",
    "    setkey(houses, Lat, Lon)\n",
    "    houses <- cbind(row.names(houses),houses)\n",
    "    colnames(houses) <- c(\"HouseId\", \"Lat\", \"Lon\", \"Count\")\n",
    "    return(houses)\n",
    "}\n",
    "housesInDetroit <- function(h){\n",
    "    library(sp)\n",
    "    library(rgdal)\n",
    "    coordinates(h) <- ~Lon + Lat\n",
    "    detroitShapeDir <- paste0(datadir, \"/City Boundaries shapefile\")\n",
    "    detroit <- readOGR(dsn=detroitShapeDir, layer = \"geo_export_941b9f41-e08a-40db-ae36-d77a7046e1a5\")\n",
    "    proj4string(h) <- proj4string(detroit)\n",
    "    hInD <- h[detroit,] #shorthand for h[!is.na(over(h,detroit)),]\n",
    "    hd <- hInD@data\n",
    "    hd <- cbind(hd,hInD@coords[,2],hInD@coords[,1])\n",
    "    names(hd) <- c(\"HouseId\",\"Count\",\"Lat\",\"Lon\")\n",
    "    #plot(hInD)\n",
    "    write.csv(x=hInD, file =\"houses-in-detroit.csv\",row.names = FALSE)\n",
    "    return(hd)\n",
    "}\n",
    "\n",
    "    houses <- buildHouses3(4)\n",
    "    houses <- housesInDetroit(houses)\n",
    "    write.csv(file = \"houses.csv\",x = houses,row.names = TRUE)\n",
    "    assign(\"houses\",houses,.GlobalEnv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Get demolition permits\n",
    "Load demolition permit data. Assign permits to previously defined houses. As a result, we have a list of demolition permits with a HouseId, if available. Many of the permits don't belong to any of the houses we've constructed above.\n",
    "Again, first define functions, then finally use them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getDemolition <- function(){\n",
    "        # if(is.null(dem)){\n",
    "            dem <- read.csv(file=\n",
    "                                \"C:/Users/setup/Documents/coursera/uw/datascience/capstone/data/detroit-demolition-permits.tsv\",\n",
    "                            sep = \"\\t\", stringsAsFactors = FALSE)\n",
    "        # }\n",
    "#         dem <- subset(dem, select=c(PERMIT_ISSUED, CASE_TYPE, BLD_PERMIT_TYPE, site_location))\n",
    "        return(dem)\n",
    "}\n",
    "\n",
    "formatDemolition <- function(dem){\n",
    "        extractCoordAdd <- function(row){\n",
    "            # site_location seems to contain the address and geocoordinates of the building to be demolished\n",
    "            loc <- row[\"site_location\"]\n",
    "            # loc is like \"4331 BARHAM\\nDetroit, MI\\n(42.394106, -82.9474)\"\n",
    "            loc <- unlist(strsplit(toString(loc),split = \"\\n\"))\n",
    "            str <- loc[1]\n",
    "            cty <- loc[2]\n",
    "            crd <- loc[3]\n",
    "            # Now we have something like (42.32544917300004, -83.06413908999997)\n",
    "            crd <- gsub(\"[()]\",\"\",crd)\n",
    "            crd <- unlist(strsplit(crd,split = \",\"))\n",
    "            lat <- crd[1]\n",
    "            lon <- crd[2]\n",
    "            coord <- c(lat, lon, str, cty)\n",
    "            return(coord)\n",
    "        }\n",
    "        dnam <- names(dem)\n",
    "        coord <- t(apply(dem, 1, extractCoordAdd))\n",
    "        dem <- cbind(as.numeric(coord[,1]), as.numeric(coord[,2]), coord[,3], coord[,4], dem)\n",
    "        dnam <- c(\"Lat\", \"Lon\", \"Street\", \"City\", dnam)\n",
    "        names(dem) <- dnam\n",
    "        dem$Street <- as.character(dem$Street)\n",
    "        dem$City <- as.character(dem$City)\n",
    "        return(dem)\n",
    "}\n",
    "\n",
    "prepareDemolition <- function(){\n",
    "    dem <- getDemolition()\n",
    "    dem <- formatDemolition(dem)\n",
    "    dem <- data.table(dem)\n",
    "    # Some 900 entries have NA for coordinates. We need to treat them separately with geocoding.\n",
    "    demToGeocode <- dem[is.na(dem$Lat),]\n",
    "    # demToGeocode <- head(demToGeocode,10)\n",
    "    # Remove from dem the entries that need to be geocoded \n",
    "    dem <- dem[!(is.na(dem$Lat)),]\n",
    "    \n",
    "    addresses <- paste0(demToGeocode$Street, \" \",gsub(\",\", \"\",demToGeocode$City))\n",
    "    geocoded <- data.frame()\n",
    "    # Start the geocoding process - address by address. geocode() function takes care of query speed limit.\n",
    "    for (ii in (1:length(addresses))){\n",
    "        if (ii %% 50 == 0){\n",
    "            print(paste(\"Working on index\", ii, \"of\", length(addresses)))    \n",
    "        }\n",
    "        #query the google geocoder - this will pause here if we are over the limit.\n",
    "        result = geoCodeAddress(addresses[ii]) \n",
    "        # print(result$status)     \n",
    "        result$index <- ii\n",
    "        #append the answer to the results file.\n",
    "        geocoded <- rbind(geocoded, result)\n",
    "        #save temporary results as we are going along\n",
    "        # saveRDS(geocoded, tempfilename)\n",
    "    }\n",
    "    # demToGeocode$accuracy <- geocoded$accuracy\n",
    "    demToGeocode$Lat <- geocoded$Lat\n",
    "    demToGeocode$Lon <- geocoded$Lon\n",
    "    # Remove the most obvious geographic outliers\n",
    "    demToGeocode <- demToGeocode[Lat %between% c(42,43) & Lon %between% c(-83.5,-81)]\n",
    "    # Finally add the geocoded entries to dem\n",
    "    dem <- rbind(dem,demToGeocode)\n",
    "    return(dem)\n",
    "}\n",
    "\n",
    "geoCodeAddress <- function(address){\n",
    "    geo_reply = geocode(address, output='all', messaging=TRUE, override_limit=TRUE)\n",
    "    #now extract the bits that we need from the returned list\n",
    "    answer <- data.frame(Lat=NA, Lon=NA, accuracy=NA, formatted_address=NA, address_type=NA, status=NA)\n",
    "    answer$status <- geo_reply$status\n",
    "    #if we are over the query limit - want to pause for an hour\n",
    "    while(geo_reply$status == \"OVER_QUERY_LIMIT\"){\n",
    "        print(\"OVER QUERY LIMIT - Pausing for 1 hour at:\") \n",
    "        time <- Sys.time()\n",
    "        print(as.character(time))\n",
    "        Sys.sleep(60*60)\n",
    "        geo_reply = geocode(address, output='all', messaging=TRUE, override_limit=TRUE)\n",
    "        answer$status <- geo_reply$status\n",
    "    }\n",
    "    if (geo_reply$status != \"OK\"){\n",
    "        return(answer)\n",
    "    }   \n",
    "    #else, extract what we need from the Google server reply into a dataframe:\n",
    "    answer$Lat <- geo_reply$results[[1]]$geometry$location$lat\n",
    "    answer$Lon <- geo_reply$results[[1]]$geometry$location$lng   \n",
    "    if (length(geo_reply$results[[1]]$types) > 0){\n",
    "        answer$accuracy <- geo_reply$results[[1]]$types[[1]]\n",
    "    }\n",
    "    answer$address_type <- paste(geo_reply$results[[1]]$types, collapse=',')\n",
    "    answer$formatted_address <- geo_reply$results[[1]]$formatted_address\n",
    "    return(answer)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to put it all together!\n",
    "Get and format the demolition permits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dem <- prepareDemolition()\n",
    "\n",
    "demolitionHouses <- function(dem, houses){\n",
    "    h <- data.table(houses)\n",
    "    setkey(h,Lat,Lon)\n",
    "    # Link demolition permits to houses\n",
    "    d <- apply(dem, 1, findInHouses3,h)\n",
    "    dem <- cbind(d, dem)\n",
    "    names(dem)[names(dem)==\"d\"] <- \"house\"\n",
    "    dem\n",
    "}\n",
    "\n",
    "findInHouses3 <- function(row, houses) {\n",
    "    # houses must be a data.table. Returns HouseId (an integer) or NA\n",
    "    rlat <- round(as.numeric(row[\"Lat\"]),digits=4)\n",
    "    rlon <- round(as.numeric(row[\"Lon\"]),digits=4)\n",
    "    res <- houses[list(rlat,rlon)]\n",
    "    res$HouseId\n",
    "}\n",
    "\n",
    "# Assign them to houses\n",
    "dh <- demolitionHouses(dem,houses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortcut\n",
    "Using the file I've saved from my dataframes, load dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dh <- read.csv(\"houses_with_demolition.csv\",stringsAsFactors = FALSE)\n",
    "# Checked in Carto that only 1 of these may fall a few meters outside Detroit --> ignore error\n",
    "dh <- data.table(dh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Prepare demolition permits for training and testing\n",
    "Many demolition permits are not associated to any of our houses. In other words there are no incidents linked to them. Let's disregard them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gh <- dh[!is.na(house)]\n",
    "sgh <- subset(gh,select=c(\"house\",\"Lat\",\"Lon\",\"PERMIT_ISSUED\",\"LEGAL_USE\",\"PARCEL_SIZE\",\"STORIES\"))\n",
    "rm(dh,gh)\n",
    "nrow(sgh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be 3573 demolition permits assigned to houses (sgh).\n",
    "Check for duplicates ie. multiple permits to the same house:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "> sum(duplicated(sgh$house))\n",
    "[1] 1090\n",
    "> sum(duplicated(sgh$house, sgh$Lat, sgh$Lon))\n",
    "[1] 1090"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally remove duplicates and prepare the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgh <- sgh[!duplicated(sgh$house),] \n",
    "n <- nrow(sgh)\n",
    "train <- sample(1:n, size=round(0.7*n),replace=FALSE)\n",
    "demtrain <- sgh[train,]\n",
    "demtest <- sgh[-train,]\n",
    "# Some crude validity tests\n",
    "sum(duplicated(sgh$house))\n",
    "max(sgh$Lat)\n",
    "max(sgh$Lon)\n",
    "\n",
    "bHouses <- data.table(HouseId = sgh$house, ToDemolition = TRUE)\n",
    "nbHouses <- houses[!(HouseId %in% sgh$house)]\n",
    "nbHouses <- data.table(HouseId = as.integer(nbHouses$HouseId), ToDemolition = FALSE)\n",
    "nbHouses <- nbHouses[sample(1:nrow(nbHouses), size=nrow(bHouses), replace=FALSE),]\n",
    "# as result, we have nrow(bHouses) = nrow(nbHouses) = 2483\n",
    "\n",
    "ttHouses <- rbind(bHouses, nbHouses)\n",
    "ttHouses[order(ttHouses$HouseId),]\n",
    "# Ordering by HouseId should distribute the blighted/nonblighted houses fairly randomly, \n",
    "# as the house numbers were generated with no reference to blight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Number of incidents per house in training/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bvc <- loadDf(\"bvCounts.csv\") #A result of previous aggregation of incidents per Lat,Lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, here's how the object in bvCounts was built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bv <- loadDf(\"Detroitbviolfromcartocsv.csv\")\n",
    "bv <- subset(bv, select=c(\"lat\", \"lon\"))\n",
    "bv$lat <- round(bv$lat,digits=4)\n",
    "bv$lon <- round(bv$lon,digits=4)\n",
    "bv <- data.table(bv)\n",
    "bv <- bv[, \":=\" (Count = .N), by= list(lat,lon)]\n",
    "# The data table operator .N adds the number of incidents in the by group to every member of the group.\n",
    "# It did not remove duplicates (aggregate to one member per group)\n",
    "bv <- unique(bv)\n",
    "names(bv)=c(\"Lat\", \"Lon\", \"Count\")\n",
    "setkey(bv,Lat,Lon)\n",
    "\n",
    "train <- loadDf(\"trainSet.csv\")\n",
    "train <- data.table(train)\n",
    "setkey(train,Lat,Lon)\n",
    "# Join the data tables\n",
    "bt <- bv[train]\n",
    "names(bt)\n",
    "# [1] \"Lat\"          \"Lon\"          \"Count\"        \"HouseId\"      \"ToDemolition\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Build simple model\n",
    "Build the model based on solely the number of incidents per case in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "btree <- tree(ToDemolition ~ Count, data= bt)\n",
    "cv.tree(btree, , prune.tree,K=5)\n",
    "plot(tree)\n",
    "text(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting model is very simple: if the number of incidents >0.5 (in practice if there are incidents) then predict TRUE = to be demolished = blighted.\n",
    "The precision is not too good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
